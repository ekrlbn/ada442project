{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score,recall_score,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE,SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank-additional/bank-additional.csv\", header=0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "\n",
      "Duplicated row count:  0\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print('\\nDuplicated row count: ' , duplicate_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset doesn't have any missing values and duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "no         3315\n",
      "unknown     803\n",
      "yes           1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_values = df['default'].value_counts()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"job\", \"marital\", \"education\" ,\"default\", \"housing\", \"loan\", \"contact\"]\n",
    "ordinal_cols = [ \"month\", \"day_of_week\"]\n",
    "numerical_cols = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "target_col = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('unknown', pd.NA, inplace=True)\n",
    "df.replace(pd.NA, np.nan, inplace=True)\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown values replaced with nan. This replacement enables data to be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "day_order = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', Pipeline(steps=[\n",
    "            ('imputer', categorical_imputer),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_cols),\n",
    "        ('ordinal', Pipeline(steps=[\n",
    "            ('imputer', categorical_imputer),\n",
    "            ('encoder', OrdinalEncoder(categories=[month_order, day_order]))\n",
    "        ]), ordinal_cols),\n",
    "        ('scaler', Pipeline(steps=[\n",
    "            ('imputer', numerical_imputer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_indices(df):\n",
    "        names = categorical_cols + ordinal_cols  \n",
    "        print(names)\n",
    "        categorical_indices = [df.columns.get_loc(col) for col in names]\n",
    "        return categorical_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week']\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[target_col],axis=1)\n",
    "y = df[target_col].map({'yes': 1, 'no': 0})\n",
    "\n",
    "\n",
    "resampling_coefficient = 0.6\n",
    "categorical_indices=return_indices(df)\n",
    "    \n",
    "resampling_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\n",
    "                \"undersampler\",\n",
    "                    RandomUnderSampler(\n",
    "                        sampling_strategy=resampling_coefficient\n",
    "                    ),\n",
    "            ),\n",
    "            (\n",
    "                \"oversampler\",\n",
    "                    SMOTENC(\n",
    "                        categorical_features=categorical_indices,\n",
    "                        sampling_strategy=\"not majority\", \n",
    "                        k_neighbors=3, \n",
    "                        n_jobs=16\n",
    "                    ),\n",
    "            ),\n",
    "        ],\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline data is imputated and encoded. After the imputation and encoding, data is oversampled using minority class with SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = ImbPipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    (\"undersampler\",RandomUnderSampler(sampling_strategy=resampling_coefficient)),\n",
    "    (\"oversampler\",SMOTE(random_state=42)),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators':[ 50,100,200,300,400,500],\n",
    "    'model__max_depth': [4, 6, 8, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10, 15]\n",
    "}\n",
    "\n",
    "scoring_rf = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring=scoring_rf, refit=\"accuracy\")\n",
    "\n",
    "grid_rf.fit(X_train,y_train )\n",
    "\n",
    "print(\"Best Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best Roc AUC Score:\", grid_rf.best_score_)\n",
    "\n",
    "best = grid_rf.best_estimator_\n",
    "\n",
    "y_pred=best.predict(X_test)\n",
    "\n",
    "results = grid_rf.cv_results_\n",
    "mean_accuracy = results['mean_test_accuracy'][grid_rf.best_index_]\n",
    "mean_precision = results['mean_test_precision'][grid_rf.best_index_]\n",
    "\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
