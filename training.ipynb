{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score,recall_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank-additional/bank-additional.csv\", header=0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "job               0\n",
      "marital           0\n",
      "education         0\n",
      "default           0\n",
      "housing           0\n",
      "loan              0\n",
      "contact           0\n",
      "month             0\n",
      "day_of_week       0\n",
      "duration          0\n",
      "campaign          0\n",
      "pdays             0\n",
      "previous          0\n",
      "poutcome          0\n",
      "emp.var.rate      0\n",
      "cons.price.idx    0\n",
      "cons.conf.idx     0\n",
      "euribor3m         0\n",
      "nr.employed       0\n",
      "y                 0\n",
      "dtype: int64\n",
      "\n",
      "Duplicated row count:  0\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print('\\nDuplicated row count: ' , duplicate_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset doesn't have any missing values and duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "no     3668\n",
      "yes     451\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_values = df['y'].value_counts()\n",
    "print(column_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"job\", \"marital\", \"default\", \"housing\", \"loan\", \"contact\", \"education\"]\n",
    "ordinal_cols = [ \"month\", \"day_of_week\"]\n",
    "numerical_cols = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "target_col = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('unknown', pd.NA, inplace=True)\n",
    "df.replace(pd.NA, np.nan, inplace=True)\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown values replaced with nan. This replacement enables data to be imputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "day_order = ['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', Pipeline(steps=[\n",
    "            ('imputer', categorical_imputer),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]), categorical_cols),\n",
    "        ('ordinal', Pipeline(steps=[\n",
    "            ('imputer', categorical_imputer),\n",
    "            ('encoder', OrdinalEncoder(categories=[month_order, day_order]))\n",
    "        ]), ordinal_cols),\n",
    "        ('scaler', Pipeline(steps=[\n",
    "            ('imputer', numerical_imputer),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numerical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''y_encoded = y.map({'yes': 1, 'no': 0})\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_sampled, y_sampled = smote.fit_resample(X_processed, y_encoded)\n",
    "\n",
    "print(\"Original class distribution:\")\n",
    "print(pd.Series(y_encoded).value_counts())\n",
    "print(\"Resampled class distribution:\")\n",
    "print(pd.Series(y_sampled).value_counts())\n",
    "\n",
    "onehot_cols = preprocessor.transformers_[0][1].named_steps['encoder'].get_feature_names_out(categorical_cols)\n",
    "all_columns = np.concatenate([onehot_cols, ordinal_cols, numerical_cols])\n",
    "X_sampled_df = pd.DataFrame(X_sampled, columns=all_columns)\n",
    "y_sampled_df = pd.DataFrame(y_sampled, columns=[target_col])\n",
    "\n",
    "df_sampled = pd.concat([X_sampled_df, y_sampled_df], axis=1)\n",
    "print(df_sampled.head())\n",
    "\n",
    "('preprocessor', preprocessor),\n",
    "('smote', SMOTE(random_state=42)),'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target_col],axis=1)\n",
    "y = df[target_col].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline data is imputated and encoded. After the imputation and encoding, data is oversampled using minority class with SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ADA\\ada442project\\ada-env\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__max_depth': 20, 'model__min_samples_split': 10, 'model__n_estimators': 300}\n",
      "Best Roc AUC Score: 0.9192716236722307\n",
      "Mean Accuracy: 0.9192716236722307\n",
      "Mean Precision: 0.7144593437276365\n",
      "Accuracy: 0.9004854368932039\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       732\n",
      "           1       0.58      0.38      0.46        92\n",
      "\n",
      "    accuracy                           0.90       824\n",
      "   macro avg       0.75      0.67      0.70       824\n",
      "weighted avg       0.89      0.90      0.89       824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators':[ 50,100,200,300,400,500],\n",
    "    'model__max_depth': [4, 6, 8, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10, 15]\n",
    "}\n",
    "\n",
    "scoring_rf = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=scoring_rf, refit=\"accuracy\")\n",
    "\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best Roc AUC Score:\", grid_rf.best_score_)\n",
    "\n",
    "best = grid_rf.best_estimator_\n",
    "\n",
    "y_pred=best.predict(X_test)\n",
    "\n",
    "results = grid_rf.cv_results_\n",
    "mean_accuracy = results['mean_test_accuracy'][grid_rf.best_index_]\n",
    "mean_precision = results['mean_test_precision'][grid_rf.best_index_]\n",
    "\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
