{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, precision_score, accuracy_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bank-additional/bank-additional.csv\", header=0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4119 entries, 0 to 4118\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             4119 non-null   int64  \n",
      " 1   job             4119 non-null   object \n",
      " 2   marital         4119 non-null   object \n",
      " 3   education       4119 non-null   object \n",
      " 4   default         4119 non-null   object \n",
      " 5   housing         4119 non-null   object \n",
      " 6   loan            4119 non-null   object \n",
      " 7   contact         4119 non-null   object \n",
      " 8   month           4119 non-null   object \n",
      " 9   day_of_week     4119 non-null   object \n",
      " 10  duration        4119 non-null   int64  \n",
      " 11  campaign        4119 non-null   int64  \n",
      " 12  pdays           4119 non-null   int64  \n",
      " 13  previous        4119 non-null   int64  \n",
      " 14  poutcome        4119 non-null   object \n",
      " 15  emp.var.rate    4119 non-null   float64\n",
      " 16  cons.price.idx  4119 non-null   float64\n",
      " 17  cons.conf.idx   4119 non-null   float64\n",
      " 18  euribor3m       4119 non-null   float64\n",
      " 19  nr.employed     4119 non-null   float64\n",
      " 20  y               4119 non-null   object \n",
      "dtypes: float64(5), int64(5), object(11)\n",
      "memory usage: 675.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "no         3315\n",
       "unknown     803\n",
       "yes           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.default.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column \"default\" is extremely unbalanced therefore can be excluded from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clean_data(df : pd.DataFrame, includeDefault = False, includeDate=False) -> pd.DataFrame:\n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned['y'] = df_cleaned['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    if (not includeDefault):\n",
    "        df_cleaned = df_cleaned.drop('default', axis=1)\n",
    "\n",
    "    if (not includeDate):\n",
    "        df_cleaned = df_cleaned.drop(['day_of_week', 'month'], axis=1)\n",
    "\n",
    "    return df_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def preprocess_data(data : pd.DataFrame, includeDate = False) -> pd.DataFrame:\n",
    "    dummies_contact = pd.get_dummies(data['contact'], prefix='contact', drop_first=True)\n",
    "\n",
    "    dummies_house = pd.get_dummies(data['housing'], prefix='housing')\n",
    "    dummies_house = dummies_house.drop('housing_unknown', axis=1)\n",
    "\n",
    "    dummies_loan = pd.get_dummies(data['loan'], prefix='loan')\n",
    "    dummies_loan  = dummies_loan.drop('loan_unknown', axis=1)\n",
    "\n",
    "\n",
    "    dummies_marital = pd.get_dummies(data['marital'], prefix='marital')\n",
    "    dummies_marital  = dummies_marital.drop('marital_unknown', axis=1)\n",
    "\n",
    "    dummies_education = pd.get_dummies(data['education'], prefix='education')\n",
    "    dummies_education  = dummies_education.drop('education_unknown', axis=1)\n",
    "\n",
    "    dummies_job = pd.get_dummies(data['job'], prefix='job')\n",
    "    dummies_job  = dummies_job.drop('job_unknown', axis=1)\n",
    "\n",
    "\n",
    "    dummies_poutcome = pd.get_dummies(data['poutcome'], prefix='poutcome')\n",
    "    dummies_poutcome  = dummies_poutcome.drop('poutcome_nonexistent', axis=1)\n",
    "\n",
    "\n",
    "    df_encoded = pd.concat([\n",
    "        data,\n",
    "        dummies_contact,\n",
    "        dummies_house,\n",
    "        dummies_loan,\n",
    "        dummies_marital,\n",
    "        dummies_education,\n",
    "        dummies_job,\n",
    "        dummies_poutcome\n",
    "    ], axis=1).drop([\n",
    "        'contact',\n",
    "        'housing',\n",
    "        'loan',\n",
    "        'marital', \n",
    "        'education', \n",
    "        'job', \n",
    "        'poutcome', \n",
    "    ], axis=1)\n",
    "\n",
    "    if 'month' in data.columns:\n",
    "        dummies_month = pd.get_dummies(data['month'], prefix='month', drop_first=True)\n",
    "        dummies_day_of_week = pd.get_dummies(data['day_of_week'], prefix='day_of_week', drop_first=True)\n",
    "\n",
    "        df_encoded = pd.concat([\n",
    "            df_encoded,\n",
    "            dummies_month,\n",
    "            dummies_day_of_week\n",
    "        ], axis=1).drop(['month' ,'day_of_week'], axis=1)\n",
    "\n",
    "    if 'default' in data.columns:\n",
    "        dummies_default = pd.get_dummies(data['default'], prefix='default')\n",
    "        dummies_default  = dummies_default.drop('default_unknown', axis=1)\n",
    "        df_encoded = pd.concat([df_encoded, dummies_default], axis=1).drop(['default'], axis=1)\n",
    "\n",
    "    return df_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clean = clean_data(df)\n",
    "df_encoded = preprocess_data(clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_encoded.drop('y', axis=1), df_encoded['y'], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_scaled = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ADA\\ada442project\\ada-env\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__max_depth': 20, 'model__min_samples_split': 15, 'model__n_estimators': 400}\n",
      "Best Accuracy Score: 0.9101729405796931\n",
      "Mean Accuracy: 0.9101729405796931\n",
      "Mean Precision: 0.6578244631185808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'model__n_estimators':[ 50,100,200,300,400,500],\n",
    "    'model__max_depth': [4, 6, 8, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5, 10, 15]\n",
    "}\n",
    "\n",
    "scoring_rf = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=scoring_rf, refit=\"accuracy\")\n",
    "\n",
    "clean_rf = clean_data(df, True, True)\n",
    "df_encoded_rf = preprocess_data(clean_rf)\n",
    "\n",
    "grid_rf.fit(df_encoded_rf.drop('y', axis=1), df_encoded_rf['y'])\n",
    "\n",
    "print(\"Best Parameters:\", grid_rf.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_rf.best_score_)\n",
    "\n",
    "results = grid_rf.cv_results_\n",
    "mean_accuracy = results['mean_test_accuracy'][grid_rf.best_index_]\n",
    "mean_precision = results['mean_test_precision'][grid_rf.best_index_]\n",
    "\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean Precision:\", mean_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'model__C': 0.1, 'model__penalty': 'l1', 'model__solver': 'liblinear'}\n",
      "Best ROC AUC Score: 0.9354564396838077\n",
      "Best Accuracy: 0.9128428434923144\n",
      "Best Precision: 0.6634194323969126\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "scoring = {\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'model__C': [0.1, 1, 10, 100],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=scoring, refit=\"roc_auc\")\n",
    "\n",
    "clean = clean_data(df, True, True)\n",
    "df_encoded = preprocess_data(clean)\n",
    "\n",
    "grid.fit(df_encoded.drop('y', axis=1), df_encoded['y'])\n",
    "\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Best ROC AUC Score:\", grid.best_score_)\n",
    "\n",
    "results = grid.cv_results_\n",
    "mean_accuracy = results['mean_test_accuracy'][grid.best_index_]\n",
    "mean_precision = results['mean_test_precision'][grid.best_index_]\n",
    "\n",
    "print(\"Best Accuracy:\", mean_accuracy)\n",
    "print(\"Best Precision:\", mean_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load and inspect the dataset\n",
    "def load_data_d(file_path):\n",
    "    df = pd.read_csv(file_path, delimiter=\";\")\n",
    "    return df\n",
    "\n",
    "def clean_data_d(df, include_default=False, include_date=False):\n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned['y'] = df_cleaned['y'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    if not include_default:\n",
    "        df_cleaned = df_cleaned.drop('default', axis=1)\n",
    "\n",
    "    if not include_date:\n",
    "        df_cleaned = df_cleaned.drop(['day_of_week', 'month'], axis=1)\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "def preprocess_data_d(df, include_date=False):\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['contact', 'housing', 'loan', 'marital', 'education', 'job', 'poutcome']\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    if include_date:\n",
    "        date_cols = ['day_of_week', 'month']\n",
    "        df_encoded = pd.get_dummies(df_encoded, columns=date_cols, drop_first=True)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "def scale_data_d(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, scaler\n",
    "\n",
    "\n",
    "def evaluate_model_d(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
